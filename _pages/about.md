---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

I am a LLM algorithm engineer in the Seed department of ByteDance. Before joining ByteDance, I was a VLM algorithm engineer at Tencent PCG. And I worked as computer vision algorithm researcher at research institute of Megvii Technology(Face++) earlier.

My research interest includes **LLM**, **Agent** and **VLM**. I have published some papers at the top international AI conferences such as AAAI, ECCV, TMM. 

# ğŸ”¥ News

<style>
  .scrollable {
    max-height: 400px; /* è®¾ç½®æœ€å¤§é«˜åº¦ */
    overflow-y: scroll; /* è®¾ç½®å‚ç›´æ»šåŠ¨æ¡ */
  }
</style>

<!-- <font color="red></font>
<a href=""></a> -->

*(Scroll down for more ...)* â¬‡ï¸

<div class="scrollable">
    <ul>
      <li><strong>2022.11</strong>: &nbsp;&nbsp;ğŸ‰ğŸ‰Our <a href="https://ojs.aaai.org/index.php/AAAI/article/view/25267/25039">Token Mixing</a> is accepted by <b>AAAI 2023</b>!</li>
      <li><strong>2022.11</strong>: &nbsp;&nbsp;ğŸ‰ğŸ‰Our <a href="https://scholar.google.com/citations?view_op=view_citation&hl=zh-CNuser=d85dtJwAAAAJ&citation_for_view=d85dtJwAAAAJ:2osOgNQ5qMEC">New paper</a> is accepted by <b>TMM 2022</b>!</li>
      <li><strong>2022.05</strong>: &nbsp;ğŸ‰ğŸ‰Our <a href="https://arxiv.org/pdf/2207.07852">Ts2-net</a> is accepted by <b>ECCV 2022</b>!</li>
      <li><strong>2021.06</strong>: &nbsp;ğŸ‰ğŸ‰Our <a href="https://arxiv.org/pdf/2106.11097">Clip2video</a> is published!</li>
    </ul>
</div>


# ğŸ“ Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">AAAI 2023</div><img src='images/token_mixing.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

ğŸ¯<img src='https://img.shields.io/badge/AAAI 2023-orange' />[Token mixing: parameter-efficient transfer learning from image-language to video-language](https://ojs.aaai.org/index.php/AAAI/article/view/25267/25039) &nbsp;
Yuqi Liu, Luhui Xu, Pengfei Xiong, Qin Jin

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">TMM 2022</div><img src='images/token_mixing.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

ğŸ¯<img src='https://scholar.google.com/citations?view_op=view_citation&hl=zh-CNuser=d85dtJwAAAAJ&citation_for_view=d85dtJwAAAAJ:2osOgNQ5qMEC' />[Transferring image-clip to video-text retrieval via temporal relations](https://arxiv.org/pdf/2207.07852) &nbsp;
Han Fang, Pengfei Xiong, Luhui Xu, Wenhan Luo

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECCV 2022</div><img src='images/Ts2-net' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

ğŸ¯<img src='https://img.shields.io/badge/ECCV 2022-orange' />[TS2-Net: Token Shift and Selection Transformer for Text-Video Retrieval](https://arxiv.org/pdf/2207.07852) &nbsp;
Yuqi Liu, Pengfei Xiong, Luhui Xu, Qin Jin

</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">arxiv</div><img src='images/Clip2video.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

ğŸ¯<img src='https://img.shields.io/badge/arxiv-orange' />[CLIP2Video: Mastering Video-Text Retrieval via Image CLIP](https://arxiv.org/pdf/2106.11097) &nbsp;
Han Fang, Pengfei Xiong, Luhui Xu, Yu Chen

</div>
</div>


# ğŸ’» Projects
- Bytedance
  - Story game dialogue based on LLM (Maoxiang)
  - Multilingual and multimodal relevance (Tiktok)
  - Multilangual and multimodal pretraining (Tiktok)
- Tencent
  - Intelligent material production of video (Tencent video)
  - Cross-modal video retrieval (Tencent video)
  - Multimodal text generation with GPT (Wechat)
- Megvii(Face++)
  - Facc-antisproofing detection with binocular
  - Image captured under-screen enhancement on mobile phone


# ğŸ“– Educations
- *2015.09 - 2018.01*, M.S. in Automation, Harbin institute of Technology (HIT)

- *2011.09 - 2015.06*, B.S. in Automation, China University of Mining and Technology (CUMT)


# ğŸ– Honors and Awards
* Tencent five-star employee 
* Beijing Artificial Intelligence Professional Intermediate Title
* National Scholarship